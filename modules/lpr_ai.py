import cv2
from ultralytics import YOLO
from paddleocr import PaddleOCR
import time
import logging

# è¨­å®š Log ä¸é¡¯ç¤ºå¤ªå¤šé›œè¨Š
logging.getLogger("ppocr").setLevel(logging.ERROR)

class LPRSystem:
    def __init__(self, yolo_path='yolov8n.pt', use_gpu_ocr=False):
        """
        åˆå§‹åŒ– LPR ç³»çµ±
        :param yolo_path: YOLO æ¨¡å‹è·¯å¾‘
        :param use_gpu_ocr: PaddleOCR æ˜¯å¦ä½¿ç”¨ GPU (Orin Nano å»ºè­° False)
        """
        print("ğŸ§  [AI] æ­£åœ¨è¼‰å…¥ YOLO æ¨¡å‹ (GPU)...")
        # ä½ çš„ç’°å¢ƒ PyTorch æ”¯æ´ GPUï¼Œæ‰€ä»¥é€™è£¡æœƒè‡ªå‹•ç”¨ GPU
        self.detector = YOLO(yolo_path)
        
        print(f"ğŸ‘€ [AI] æ­£åœ¨è¼‰å…¥ PaddleOCR (GPU={use_gpu_ocr})...")
        # lang='en' è¾¨è­˜æ•¸å­—èˆ‡è‹±æ–‡è¼ƒæº–
        self.ocr = PaddleOCR(use_textline_orientation=True, lang='en')
        
        # è¨­å®šè¦åµæ¸¬çš„é¡åˆ¥ (COCO dataset: 2=car, 5=bus, 7=truck)
        self.target_classes = [2, 5, 7]

    def process_frame(self, frame):
        """
        è™•ç†å–®å¼µå½±åƒï¼šåµæ¸¬è»Šè¼› -> (è‹¥æœ‰è»Š) -> è¾¨è­˜è»Šç‰Œ
        å›å‚³: (annotated_frame, plate_text)
        """
        # 1. YOLO åµæ¸¬
        results = self.detector(frame, verbose=False, conf=0.5)
        detections = results[0]
        
        has_vehicle = False
        plate_text = None
        
        # éæ¿¾åµæ¸¬åˆ°çš„ç‰©ä»¶
        for box in detections.boxes:
            cls_id = int(box.cls[0])
            if cls_id in self.target_classes:
                has_vehicle = True
                break
        
        # 2. è‹¥æœ‰è»Šï¼Œé€²è¡Œ OCR
        if has_vehicle:
            # é€™è£¡ç‚ºäº†æ•ˆèƒ½ï¼Œä½ å¯ä»¥åªè£åˆ‡ bbox å‡ºä¾†åš OCRï¼Œé€™è£¡å…ˆç¤ºç¯„å…¨åœ–
            ocr_results = self.ocr.ocr(frame, cls=False)
            
            if ocr_results and ocr_results[0]:
                # æ‰¾å‡ºä¿¡å¿ƒåº¦æœ€é«˜çš„æ–‡å­—å€å¡Š
                best_match = max(ocr_results[0], key=lambda x: x[1][1])
                text, conf = best_match[1]
                
                # ç°¡å–®éæ¿¾ï¼šè»Šç‰Œé€šå¸¸å¤§æ–¼ 4 ç¢¼
                if len(text) > 4:
                    plate_text = text

        # ç¹ªè£½ YOLO åµæ¸¬æ¡†
        annotated_frame = detections.plot()
        
        # è‹¥æœ‰è¾¨è­˜åˆ°æ–‡å­—ï¼Œç•«åœ¨å·¦ä¸Šè§’
        if plate_text:
            cv2.putText(annotated_frame, f"Plate: {plate_text}", 
                        (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

        return annotated_frame, plate_text

# --- å–®å…ƒæ¸¬è©¦å€å¡Š ---
if __name__ == "__main__":
    print("ğŸ”§ é€²å…¥ AI è¾¨è­˜å–®å…ƒæ¸¬è©¦æ¨¡å¼...")
    # ä¸‹è¼‰ä¸€å¼µç¶²è·¯åœ–ç‰‡æ¸¬è©¦
    import numpy as np
    import urllib.request
    
    lpr = LPRSystem()
    
    url = 'https://ultralytics.com/images/bus.jpg'
    print(f"ğŸ“¥ ä¸‹è¼‰æ¸¬è©¦åœ–ç‰‡: {url}")
    req = urllib.request.urlopen(url)
    arr = np.asarray(bytearray(req.read()), dtype=np.uint8)
    img = cv2.imdecode(arr, -1)
    
    # åŸ·è¡Œè¾¨è­˜
    result_img, text = lpr.process_frame(img)
    print(f"ğŸ” è¾¨è­˜çµæœ: {text}")
